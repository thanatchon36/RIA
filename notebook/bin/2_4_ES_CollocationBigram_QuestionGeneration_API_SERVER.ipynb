{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "890431d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK !\n"
     ]
    }
   ],
   "source": [
    "#Default\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:,}'.format\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "def reset(df):\n",
    "    cols = df.columns\n",
    "    return df.reset_index()[cols]\n",
    "def print_counts(df):\n",
    "    cols = df.columns\n",
    "    for each in cols:\n",
    "        print(each)\n",
    "        print(df[each].value_counts())\n",
    "        print('______________________________________')\n",
    "# ~\n",
    "#Default Ending\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "print('OK !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d01f83c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK !\n"
     ]
    }
   ],
   "source": [
    "from haystack.utils import clean_wiki_text, convert_files_to_dicts, fetch_archive_from_http, print_answers\n",
    "from haystack.nodes import DensePassageRetriever, EmbeddingRetriever, FARMReader, EntityExtractor\n",
    "from haystack.document_stores import ElasticsearchDocumentStore\n",
    "\n",
    "import torch\n",
    "\n",
    "print('OK !')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5656cf0",
   "metadata": {},
   "source": [
    "# Embedding Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "409ddfad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For EmbeddingRetriever\n",
    "similarity_type = \"cosine\"\n",
    "\n",
    "container_name = \"localhost\"\n",
    "\n",
    "er_co = ElasticsearchDocumentStore(host=container_name, port = \"9200\", index=\"production_er_bigram_collocation\",\n",
    "                                           similarity=similarity_type, embedding_dim=768)\n",
    "\n",
    "er_qg = ElasticsearchDocumentStore(host=container_name, port = \"9200\", index=\"production_er_question_generation\",\n",
    "                                           similarity=similarity_type, embedding_dim=768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25186bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pdftotext version 4.03 [www.xpdfreader.com]\n",
      "Copyright 1996-2021 Glyph & Cog, LLC\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import TextConverter, PDFToTextConverter, DocxToTextConverter, PreProcessor\n",
    "\n",
    "converter = PDFToTextConverter(remove_numeric_tables=False, valid_languages = [\"en\"])\n",
    "\n",
    "print('OK !')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f604e32e",
   "metadata": {},
   "source": [
    "# Set document_store "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca25b07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store = er_co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b9a0b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py38hay/lib/python3.8/site-packages/spacy/util.py:837: UserWarning: [W095] Model 'en_core_web_md' (3.2.0) was trained with spaCy v3.2 and may not be 100% compatible with the current version (3.3.0.dev0). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['the title']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from itertools import combinations\n",
    "\n",
    "# Set globals\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "def pre_process(titles):\n",
    "    \"\"\"\n",
    "    Pre-processes titles by removing stopwords and lemmatizing text.\n",
    "    :param titles: list of strings, contains target titles,.\n",
    "    :return: preprocessed_title_docs, list containing pre-processed titles.\n",
    "    \"\"\"\n",
    "\n",
    "    # Preprocess all the titles\n",
    "    title_docs = [nlp(x) for x in titles]\n",
    "    preprocessed_title_docs = []\n",
    "    lemmatized_tokens = []\n",
    "    for title_doc in title_docs:\n",
    "        for token in title_doc:\n",
    "            if not token.is_stop:\n",
    "                lemmatized_tokens.append(token.lemma_)\n",
    "        preprocessed_title_docs.append(\" \".join(lemmatized_tokens))\n",
    "        del lemmatized_tokens[\n",
    "            :\n",
    "            ]  # empty the lemmatized tokens list as the code moves onto a new title\n",
    "\n",
    "    return preprocessed_title_docs\n",
    "\n",
    "def similarity_filter(titles):\n",
    "    \"\"\"\n",
    "    Recursively check if titles pass a similarity filter.\n",
    "    :param titles: list of strings, contains titles.\n",
    "    If the function finds titles that fail the similarity test, the above param will be the function output.\n",
    "    :return: this method upon itself unless there are no similar titles; in that case the feed that was passed\n",
    "    in is returned.\n",
    "    \"\"\"\n",
    "\n",
    "    # Preprocess titles\n",
    "    preprocessed_title_docs = pre_process(titles)\n",
    "\n",
    "    # Remove similar titles\n",
    "    all_summary_pairs = list(combinations(preprocessed_title_docs, 2))\n",
    "    similar_titles = []\n",
    "    for pair in all_summary_pairs:\n",
    "        title1 = nlp(pair[0])\n",
    "        title2 = nlp(pair[1])\n",
    "        similarity = title1.similarity(title2)\n",
    "        if similarity > 0.8:\n",
    "            similar_titles.append(pair)\n",
    "\n",
    "    titles_to_remove = []\n",
    "    for a_title in similar_titles:\n",
    "        # Get the index of the first title in the pair\n",
    "        index_for_removal = preprocessed_title_docs.index(a_title[0])\n",
    "        titles_to_remove.append(index_for_removal)\n",
    "\n",
    "    # Get indices of similar titles and remove them\n",
    "    similar_title_counts = set(titles_to_remove)\n",
    "    similar_titles = [\n",
    "        x[1] for x in enumerate(titles) if x[0] in similar_title_counts\n",
    "    ]\n",
    "\n",
    "    # Exit the recursion if there are no longer any similar titles\n",
    "    if len(similar_title_counts) == 0:\n",
    "        return titles\n",
    "\n",
    "    # Continue the recursion if there are still titles to remove\n",
    "    else:\n",
    "        # Remove similar titles from the next input\n",
    "        for title in similar_titles:\n",
    "            idx = titles.index(title)\n",
    "            titles.pop(idx)\n",
    "            \n",
    "        return similarity_filter(titles)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    your_title_list = ['a title', 'the title']\n",
    "    similarity_filter(your_title_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c5bec44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CPU\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 0\n",
      "INFO - haystack.nodes.retriever.dense -  Init retriever using embeddings of model all-mpnet-base-v1\n"
     ]
    }
   ],
   "source": [
    "er_retriever = EmbeddingRetriever(\n",
    "   document_store=document_store,\n",
    "   embedding_model=\"all-mpnet-base-v1\",\n",
    "   model_format=\"sentence_transformers\",\n",
    "   use_gpu = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0d0cbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CPU\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 0\n",
      "INFO - haystack.nodes.retriever.dense -  Init retriever using embeddings of model all-mpnet-base-v1\n"
     ]
    }
   ],
   "source": [
    "qg_er_retriever = EmbeddingRetriever(\n",
    "   document_store=er_qg,\n",
    "   embedding_model=\"all-mpnet-base-v1\",\n",
    "   model_format=\"sentence_transformers\",\n",
    "   use_gpu = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8d168d",
   "metadata": {},
   "source": [
    "# Set API Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c941b8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK !\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from haystack.pipelines import DocumentSearchPipeline\n",
    "\n",
    "print('OK !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7536bc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/haystack_collocation', methods=['POST'])\n",
    "def haystack_collocation():\n",
    "    query_list = []\n",
    "    if request.method == 'POST':\n",
    "        body = request.get_json()\n",
    "        retriever_pipe = DocumentSearchPipeline(er_retriever)\n",
    "        prediction = retriever_pipe.run(\n",
    "            query=body['query'], params={\"Retriever\": {\"top_k\": 24},\n",
    "                                         \"filters\": body['filters'],\n",
    "                                         }\n",
    "        )\n",
    "        doc_list = [each.__dict__ for each in prediction['documents']]\n",
    "        prediction['documents'] = doc_list\n",
    "        suggested_co_list = prediction['documents']\n",
    "        suggested_co_list = [each['content'] for each in suggested_co_list]\n",
    "        suggested_co_list = similarity_filter(suggested_co_list)\n",
    "        return {'suggested_keywords': suggested_co_list}, 201\n",
    "    \n",
    "@app.route('/haystack_question_generation', methods=['POST'])\n",
    "def haystack_question_generation():\n",
    "    query_list = []\n",
    "    if request.method == 'POST':\n",
    "        body = request.get_json()\n",
    "        retriever_pipe = DocumentSearchPipeline(qg_er_retriever)\n",
    "        prediction = retriever_pipe.run(\n",
    "            query=body['query'], params={\"Retriever\": {\"top_k\": 24},\n",
    "                                         \"filters\": body['filters'],\n",
    "                                         }\n",
    "        )\n",
    "        doc_list = [each.__dict__ for each in prediction['documents']]\n",
    "        prediction['documents'] = doc_list\n",
    "        suggested_co_list = prediction['documents']\n",
    "        suggested_co_list = [each['content'] for each in suggested_co_list]\n",
    "        suggested_co_list = similarity_filter(suggested_co_list)\n",
    "        return {'suggested_keywords': suggested_co_list}, 201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "044aec99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - werkzeug -   * Running on http://127.0.0.1:7101/ (Press CTRL+C to quit)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58e66fae9fc94e2abe4ca508c5dc7ef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - werkzeug -  127.0.0.1 - - [30/Apr/2022 12:07:55] \"\u001b[35m\u001b[1mPOST /haystack_question_generation HTTP/1.1\u001b[0m\" 201 -\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9082a69bd33f4adc8368e4a1f7b03ee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - werkzeug -  127.0.0.1 - - [30/Apr/2022 12:09:15] \"\u001b[35m\u001b[1mPOST /haystack_collocation HTTP/1.1\u001b[0m\" 201 -\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a5cdae59a184d2fb088c142b8948e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - werkzeug -  127.0.0.1 - - [30/Apr/2022 12:11:46] \"\u001b[35m\u001b[1mPOST /haystack_question_generation HTTP/1.1\u001b[0m\" 201 -\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccc9f424db554a979a5ca60235c049fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - werkzeug -  127.0.0.1 - - [30/Apr/2022 12:12:58] \"\u001b[35m\u001b[1mPOST /haystack_collocation HTTP/1.1\u001b[0m\" 201 -\n"
     ]
    }
   ],
   "source": [
    "app.run(port = 7101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0f4e4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py38hay]",
   "language": "python",
   "name": "conda-env-py38hay-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
