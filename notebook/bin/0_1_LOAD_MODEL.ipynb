{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d23b033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK !\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever, EmbeddingRetriever, FARMReader, EntityExtractor\n",
    "from haystack.document_stores import ElasticsearchDocumentStore\n",
    "\n",
    "print('OK !')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af47fcc4",
   "metadata": {},
   "source": [
    "# Load Retriver Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fe927ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CPU\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 0\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Could not find facebook/dpr-question_encoder-single-nq-base locally.\n",
      "INFO - haystack.modeling.model.language_model -  Looking on Transformers Model Hub (in local cache and online)...\n",
      "INFO - haystack.modeling.model.language_model -  Loaded facebook/dpr-question_encoder-single-nq-base\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Could not find facebook/dpr-ctx_encoder-single-nq-base locally.\n",
      "INFO - haystack.modeling.model.language_model -  Looking on Transformers Model Hub (in local cache and online)...\n",
      "INFO - haystack.modeling.model.language_model -  Loaded facebook/dpr-ctx_encoder-single-nq-base\n"
     ]
    }
   ],
   "source": [
    "document_store = ElasticsearchDocumentStore(host=\"localhost\", port = \"9200\", index=\"document_100\",\n",
    "                                           similarity='dot_product')\n",
    "\n",
    "retriever = DensePassageRetriever(\n",
    "    document_store=document_store,\n",
    "    query_embedding_model=\"facebook/dpr-question_encoder-single-nq-base\",\n",
    "    passage_embedding_model=\"facebook/dpr-ctx_encoder-single-nq-base\",\n",
    "    max_seq_len_query=64,\n",
    "    max_seq_len_passage=256,\n",
    "    batch_size=16,\n",
    "    use_gpu=True,\n",
    "    embed_title=True,\n",
    "    use_fast_tokenizers=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d89595c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.model.biadaptive_model -  prediction_head saving\n"
     ]
    }
   ],
   "source": [
    "retriever.save('DPR-retriever')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fec7b8ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CPU\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 0\n",
      "INFO - haystack.nodes.retriever.dense -  Init retriever using embeddings of model sentence-transformers/multi-qa-mpnet-base-dot-v1\n"
     ]
    }
   ],
   "source": [
    "#Auto-save for the first time\n",
    "\n",
    "document_store = ElasticsearchDocumentStore(host=\"localhost\", port = \"9200\", index=\"document_100\",\n",
    "                                           similarity='cosine')\n",
    "\n",
    "retriever_2 = EmbeddingRetriever(\n",
    "    document_store=document_store,\n",
    "    embedding_model=\"sentence-transformers/multi-qa-mpnet-base-dot-v1\",\n",
    "    model_format=\"sentence_transformers\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de36657",
   "metadata": {},
   "source": [
    "# Load Reader Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f677967",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CPU\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 0\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Could not find deepset/roberta-base-squad2 locally.\n",
      "INFO - haystack.modeling.model.language_model -  Looking on Transformers Model Hub (in local cache and online)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "092f45c5a3f2440eabf92314fadf01db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed9e5c271efb4584b619f55e83e6bd79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/473M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.model.language_model -  Loaded deepset/roberta-base-squad2\n",
      "WARNING - haystack.modeling.logger -  Failed to log params: Changing param values is not allowed. Param with key='prediction_heads' was already logged with value='TextSimilarityHead' for run ID='ef6a21e3dd584497b52757cf04c06012'. Attempted logging new value 'QuestionAnsweringHead'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef19ea19feee4970ac5491c7442a1a44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0524b748f18841e5801bb5d89a8f344a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f17d4eda9a7400694dfa0955ed37f9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3bf9fcbc2aa47b1b91797cf1d1c3360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/79.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.modeling.logger -  Failed to log params: Changing param values is not allowed. Param with key='processor' was already logged with value='TextSimilarityProcessor' for run ID='ef6a21e3dd584497b52757cf04c06012'. Attempted logging new value 'SquadProcessor'.\n",
      "INFO - haystack.modeling.logger -  ML Logging is turned off. No parameters, metrics or artifacts will be logged to MLFlow.\n",
      "INFO - haystack.modeling.utils -  Using devices: CPU\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 0\n",
      "INFO - haystack.modeling.infer -  Got ya 7 parallel workers to do inference ...\n",
      "INFO - haystack.modeling.infer -   0    0    0    0    0    0    0 \n",
      "INFO - haystack.modeling.infer -  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\\n",
      "INFO - haystack.modeling.infer -  /'\\  / \\  /'\\  /'\\  / \\  / \\  /'\\\n"
     ]
    }
   ],
   "source": [
    "reader = FARMReader(\"deepset/roberta-base-squad2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33ec98bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.reader.farm -  Saving reader model to roberta-base-squad2-reader\n"
     ]
    }
   ],
   "source": [
    "reader.save('roberta-base-squad2-reader')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbed87d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CPU\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 0\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Could not find deepset/minilm-uncased-squad2 locally.\n",
      "INFO - haystack.modeling.model.language_model -  Looking on Transformers Model Hub (in local cache and online)...\n",
      "INFO - haystack.modeling.model.language_model -  Loaded deepset/minilm-uncased-squad2\n",
      "INFO - haystack.modeling.logger -  ML Logging is turned off. No parameters, metrics or artifacts will be logged to MLFlow.\n",
      "INFO - haystack.modeling.utils -  Using devices: CPU\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 0\n",
      "INFO - haystack.modeling.infer -  Got ya 7 parallel workers to do inference ...\n",
      "INFO - haystack.modeling.infer -   0    0    0    0    0    0    0 \n",
      "INFO - haystack.modeling.infer -  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\\n",
      "INFO - haystack.modeling.infer -  /'\\  / \\  /'\\  /'\\  / \\  / \\  /'\\\n"
     ]
    }
   ],
   "source": [
    "reader_2 = FARMReader(\"deepset/minilm-uncased-squad2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3abdb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.reader.farm -  Saving reader model to minilm-uncased-squad2-reader\n"
     ]
    }
   ],
   "source": [
    "reader_2.save('minilm-uncased-squad2-reader')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4169b3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CPU\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 0\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Could not find ahotrod/albert_xxlargev1_squad2_512 locally.\n",
      "INFO - haystack.modeling.model.language_model -  Looking on Transformers Model Hub (in local cache and online)...\n",
      "INFO - haystack.modeling.model.language_model -  Loaded ahotrod/albert_xxlargev1_squad2_512\n",
      "INFO - haystack.modeling.logger -  ML Logging is turned off. No parameters, metrics or artifacts will be logged to MLFlow.\n",
      "INFO - haystack.modeling.utils -  Using devices: CPU\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 0\n",
      "INFO - haystack.modeling.infer -  Got ya 7 parallel workers to do inference ...\n",
      "INFO - haystack.modeling.infer -   0    0    0    0    0    0    0 \n",
      "INFO - haystack.modeling.infer -  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\\n",
      "INFO - haystack.modeling.infer -  /'\\  / \\  /'\\  /'\\  / \\  / \\  /'\\\n"
     ]
    }
   ],
   "source": [
    "reader_3 = FARMReader(\"ahotrod/albert_xxlargev1_squad2_512\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4b19122",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.reader.farm -  Saving reader model to albert_xxlargev1_squad2_512-reader\n"
     ]
    }
   ],
   "source": [
    "reader_3.save('albert_xxlargev1_squad2_512-reader')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bd9ab9",
   "metadata": {},
   "source": [
    "# NER Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d83e83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CPU\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 0\n"
     ]
    }
   ],
   "source": [
    "#Auto-save for the first time\n",
    "\n",
    "entity_extractor = EntityExtractor(model_name_or_path=\"dslim/bert-base-NER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b3ff96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a6383d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03922ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8211504",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py38hay]",
   "language": "python",
   "name": "conda-env-py38hay-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
