{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "890431d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK !\n"
     ]
    }
   ],
   "source": [
    "#Default\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:,}'.format\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "def reset(df):\n",
    "    cols = df.columns\n",
    "    return df.reset_index()[cols]\n",
    "def print_counts(df):\n",
    "    cols = df.columns\n",
    "    for each in cols:\n",
    "        print(each)\n",
    "        print(df[each].value_counts())\n",
    "        print('______________________________________')\n",
    "        \n",
    "def flatten(list_1):\n",
    "    list_2 = []\n",
    "    for each in list(list_1):\n",
    "        try:\n",
    "            for each_2 in each:\n",
    "                list_2.append(each_2)\n",
    "        except:\n",
    "            pass\n",
    "    return list_2\n",
    "        \n",
    "# ~\n",
    "#Default Ending\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "print('OK !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d01f83c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.base -  Numba not found, replacing njit() with no-op implementation. Enable it with 'pip install numba'.\n",
      "INFO - haystack.modeling.model.optimization -  apex not found, won't use it. See https://nvidia.github.io/apex/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK !\n"
     ]
    }
   ],
   "source": [
    "from haystack.utils import clean_wiki_text, convert_files_to_dicts, fetch_archive_from_http, print_answers\n",
    "from haystack.nodes import DensePassageRetriever, EmbeddingRetriever, FARMReader, EntityExtractor, TfidfRetriever\n",
    "from haystack.document_stores import ElasticsearchDocumentStore\n",
    "from haystack.pipelines import ExtractiveQAPipeline, DocumentSearchPipeline\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "print('OK !')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5656cf0",
   "metadata": {},
   "source": [
    "# Embedding Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1ed70ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For EmbeddingRetriever\n",
    "similarity_type = \"cosine\"\n",
    "\n",
    "container_name = \"es1\"\n",
    "\n",
    "er_100 = ElasticsearchDocumentStore(host=container_name, port = \"9200\", index=\"production_er_100\",\n",
    "                                           similarity=similarity_type, embedding_dim=768)\n",
    "er_200 = ElasticsearchDocumentStore(host=container_name, port = \"9200\", index=\"production_er_200\",\n",
    "                                           similarity=similarity_type, embedding_dim=768)\n",
    "er_300 = ElasticsearchDocumentStore(host=container_name, port = \"9200\", index=\"production_er_300\",\n",
    "                                           similarity=similarity_type, embedding_dim=768)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7958aa03",
   "metadata": {},
   "source": [
    "# Dense Passage Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "562bf40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For DensePassageRetriever\n",
    "similarity_type = \"dot_product\"\n",
    "\n",
    "dpr_100 = ElasticsearchDocumentStore(host=container_name, port = \"9200\", index=\"production_dpr_100\",\n",
    "                                           similarity=similarity_type)\n",
    "dpr_200 = ElasticsearchDocumentStore(host=container_name, port = \"9200\", index=\"production_dpr_200\",\n",
    "                                           similarity=similarity_type)\n",
    "dpr_300 = ElasticsearchDocumentStore(host=container_name, port = \"9200\", index=\"production_dpr_300\",\n",
    "                                           similarity=similarity_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f604e32e",
   "metadata": {},
   "source": [
    "# Set document_store "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca25b07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store_list = [er_200, dpr_200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02601e8a",
   "metadata": {},
   "source": [
    "# Set Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df49f3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - backoff -  Backing off send_request(...) for 0.2s (requests.exceptions.SSLError: HTTPSConnectionPool(host='tm.hs.deepset.ai', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)'))))\n",
      "INFO - backoff -  Backing off send_request(...) for 0.2s (requests.exceptions.SSLError: HTTPSConnectionPool(host='tm.hs.deepset.ai', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)'))))\n",
      "INFO - haystack.nodes.retriever.sparse -  Found 18455 candidate paragraphs from 18455 docs in DB\n",
      "INFO - backoff -  Backing off send_request(...) for 3.9s (requests.exceptions.SSLError: HTTPSConnectionPool(host='tm.hs.deepset.ai', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)'))))\n",
      "WARNING - haystack.nodes.base -  Unnamed __init__ parameters will not be saved to YAML if Pipeline.save_to_yaml() is called!\n"
     ]
    }
   ],
   "source": [
    "tfidf_retriever = TfidfRetriever(document_store_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "085264a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0, CUDA:1\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 2\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at ../shared_data/thanatcc/RIA_Model/DPR-retriever/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded ../shared_data/thanatcc/RIA_Model/DPR-retriever/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at ../shared_data/thanatcc/RIA_Model/DPR-retriever/passage_encoder\n",
      "ERROR - backoff -  Giving up send_request(...) after 4 tries (requests.exceptions.SSLError: HTTPSConnectionPool(host='tm.hs.deepset.ai', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)'))))\n",
      "ERROR - posthog -  error uploading: HTTPSConnectionPool(host='tm.hs.deepset.ai', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)')))\n",
      "INFO - haystack.modeling.model.language_model -  Loaded ../shared_data/thanatcc/RIA_Model/DPR-retriever/passage_encoder\n",
      "INFO - backoff -  Backing off send_request(...) for 0.2s (requests.exceptions.SSLError: HTTPSConnectionPool(host='tm.hs.deepset.ai', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)'))))\n",
      "INFO - backoff -  Backing off send_request(...) for 1.3s (requests.exceptions.SSLError: HTTPSConnectionPool(host='tm.hs.deepset.ai', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)'))))\n"
     ]
    }
   ],
   "source": [
    "dpr_retriever = DensePassageRetriever(\n",
    "    document_store=document_store_list[1],\n",
    "    query_embedding_model=\"../shared_data/thanatcc/RIA_Model/DPR-retriever/query_encoder\",\n",
    "    passage_embedding_model=\"../shared_data/thanatcc/RIA_Model/DPR-retriever/passage_encoder\",\n",
    "    max_seq_len_query=64,\n",
    "    max_seq_len_passage=256,\n",
    "    batch_size=16,\n",
    "    use_gpu=True,\n",
    "    embed_title=True,\n",
    "    use_fast_tokenizers=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "816a22de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0, CUDA:1\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 2\n",
      "INFO - haystack.nodes.retriever.dense -  Init retriever using embeddings of model ../shared_data/thanatcc/RIA_Model/all-mpnet-base-v1\n"
     ]
    }
   ],
   "source": [
    "er_retriever = EmbeddingRetriever(\n",
    "   document_store=document_store_list[0],\n",
    "   embedding_model=\"../shared_data/thanatcc/RIA_Model/all-mpnet-base-v1\",\n",
    "   model_format=\"sentence_transformers\",\n",
    "   use_gpu = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77f96b9",
   "metadata": {},
   "source": [
    "# Set Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a94033cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reader_path = \"../shared_data/thanatcc/RIA_Model/albert_xxlargev1_squad2_512-reader\"\n",
    "reader_path = \"../shared_data/thanatcc/RIA_Model/minilm-uncased-squad2-reader\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4ada741",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at ../shared_data/thanatcc/RIA_Model/minilm-uncased-squad2-reader\n",
      "INFO - backoff -  Backing off send_request(...) for 1.0s (requests.exceptions.SSLError: HTTPSConnectionPool(host='tm.hs.deepset.ai', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)'))))\n",
      "INFO - haystack.modeling.model.language_model -  Loaded ../shared_data/thanatcc/RIA_Model/minilm-uncased-squad2-reader\n",
      "INFO - haystack.modeling.model.adaptive_model -  Found files for loading 1 prediction heads\n",
      "WARNING - haystack.modeling.model.prediction_head -  Some unused parameters are passed to the QuestionAnsweringHead. Might not be a problem. Params: {\"training\": false, \"num_labels\": 2, \"ph_output_type\": \"per_token_squad\", \"model_type\": \"span_classification\", \"label_tensor_name\": \"question_answering_label_ids\", \"label_list\": [\"start_token\", \"end_token\"], \"metric\": \"squad\", \"name\": \"QuestionAnsweringHead\"}\n",
      "INFO - haystack.modeling.model.prediction_head -  Loading prediction head from ../shared_data/thanatcc/RIA_Model/minilm-uncased-squad2-reader/prediction_head_0.bin\n",
      "WARNING - haystack.modeling.logger -  Failed to log params: Changing param values is not allowed. Param with key='prediction_heads' was already logged with value='TextSimilarityHead' for run ID='6b1f49b62e4a43169d1bb20184b4413d'. Attempted logging new value 'QuestionAnsweringHead'.\n",
      "WARNING - haystack.modeling.logger -  Failed to log params: Changing param values is not allowed. Param with key='processor' was already logged with value='TextSimilarityProcessor' for run ID='6b1f49b62e4a43169d1bb20184b4413d'. Attempted logging new value 'SquadProcessor'.\n",
      "INFO - haystack.modeling.data_handler.processor -  Initialized processor without tasks. Supply `metric` and `label_list` to the constructor for using the default task or add a custom task later via processor.add_task()\n",
      "INFO - haystack.modeling.logger -  ML Logging is turned off. No parameters, metrics or artifacts will be logged to MLFlow.\n",
      "INFO - haystack.modeling.utils -  Using devices: CUDA\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.infer -  Got ya 7 parallel workers to do inference ...\n",
      "INFO - haystack.modeling.infer -   0     0     0     0     0     0     0  \n",
      "INFO - haystack.modeling.infer -  /w\\   /w\\   /w\\   /w\\   /w\\   /w\\   /w\\ \n",
      "INFO - haystack.modeling.infer -  /'\\   / \\   /'\\   /'\\   / \\   / \\   /'\\ \n"
     ]
    }
   ],
   "source": [
    "reader_1 = FARMReader(model_name_or_path=reader_path, \n",
    "                      use_gpu=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adc7bfbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader_1.__dict__['use_gpu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f6c2053",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at ../shared_data/thanatcc/RIA_Model/minilm-uncased-squad2-reader\n",
      "ERROR - backoff -  Giving up send_request(...) after 4 tries (requests.exceptions.SSLError: HTTPSConnectionPool(host='tm.hs.deepset.ai', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)'))))\n",
      "ERROR - posthog -  error uploading: HTTPSConnectionPool(host='tm.hs.deepset.ai', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)')))\n",
      "INFO - haystack.modeling.model.language_model -  Loaded ../shared_data/thanatcc/RIA_Model/minilm-uncased-squad2-reader\n",
      "INFO - haystack.modeling.model.adaptive_model -  Found files for loading 1 prediction heads\n",
      "WARNING - haystack.modeling.model.prediction_head -  Some unused parameters are passed to the QuestionAnsweringHead. Might not be a problem. Params: {\"training\": false, \"num_labels\": 2, \"ph_output_type\": \"per_token_squad\", \"model_type\": \"span_classification\", \"label_tensor_name\": \"question_answering_label_ids\", \"label_list\": [\"start_token\", \"end_token\"], \"metric\": \"squad\", \"name\": \"QuestionAnsweringHead\"}\n",
      "INFO - haystack.modeling.model.prediction_head -  Loading prediction head from ../shared_data/thanatcc/RIA_Model/minilm-uncased-squad2-reader/prediction_head_0.bin\n",
      "INFO - haystack.modeling.data_handler.processor -  Initialized processor without tasks. Supply `metric` and `label_list` to the constructor for using the default task or add a custom task later via processor.add_task()\n",
      "INFO - haystack.modeling.logger -  ML Logging is turned off. No parameters, metrics or artifacts will be logged to MLFlow.\n",
      "INFO - haystack.modeling.utils -  Using devices: CUDA\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.infer -  Got ya 7 parallel workers to do inference ...\n",
      "INFO - haystack.modeling.infer -   0     0     0     0     0     0     0  \n",
      "INFO - haystack.modeling.infer -  /w\\   /w\\   /w\\   /w\\   /w\\   /w\\   /w\\ \n",
      "INFO - haystack.modeling.infer -  /'\\   / \\   /'\\   /'\\   / \\   / \\   /'\\ \n"
     ]
    }
   ],
   "source": [
    "reader_2 = FARMReader(model_name_or_path=reader_path, \n",
    "                      use_gpu=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "158b2140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader_2.__dict__['use_gpu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9093138e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<haystack.nodes.reader.farm.FARMReader at 0x7f875042d7f0>,\n",
       " <haystack.nodes.reader.farm.FARMReader at 0x7f865bc4a070>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<haystack.nodes.reader.farm.FARMReader at 0x7f875042d7f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader_list = [reader_1, reader_2]\n",
    "reader_list\n",
    "\n",
    "random.choice(reader_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff166104",
   "metadata": {},
   "source": [
    "# Set Meta Filter Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a67debf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - backoff -  Backing off send_request(...) for 0.0s (requests.exceptions.SSLError: HTTPSConnectionPool(host='tm.hs.deepset.ai', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)'))))\n",
      "INFO - backoff -  Backing off send_request(...) for 0.6s (requests.exceptions.SSLError: HTTPSConnectionPool(host='tm.hs.deepset.ai', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)'))))\n",
      "INFO - backoff -  Backing off send_request(...) for 0.9s (requests.exceptions.SSLError: HTTPSConnectionPool(host='tm.hs.deepset.ai', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)'))))\n",
      "ERROR - backoff -  Giving up send_request(...) after 4 tries (requests.exceptions.SSLError: HTTPSConnectionPool(host='tm.hs.deepset.ai', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)'))))\n",
      "ERROR - posthog -  error uploading: HTTPSConnectionPool(host='tm.hs.deepset.ai', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)')))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.5 s, sys: 1.23 s, total: 17.7 s\n",
      "Wall time: 27.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "meta_list = list(document_store_list[0])\n",
    "meta_list = [each.__dict__['meta'] for each in meta_list]\n",
    "meta_df = pd.DataFrame(meta_list)\n",
    "\n",
    "# By Sentence\n",
    "main_col_list = ['central_bank', 'keyword']\n",
    "\n",
    "# Editing this will depend on NER models\n",
    "alt_col_list = ['ORG', 'LOC', 'PER', 'MISC']\n",
    "\n",
    "fil_col_list = main_col_list + alt_col_list\n",
    "min_count = 3\n",
    "meta_fil_dict = {}\n",
    "for col in fil_col_list:\n",
    "    if col in alt_col_list and col in list(meta_df.columns):\n",
    "        temp_df = pd.DataFrame(flatten(list(meta_df[col].values)))[0].value_counts().reset_index()\n",
    "    elif col in main_col_list and col in list(meta_df.columns):\n",
    "        temp_df = pd.DataFrame(list(meta_df[col].values))[0].value_counts().reset_index()\n",
    "    \n",
    "    if col in list(meta_df.columns):\n",
    "        temp_df = temp_df[temp_df[0] >= min_count]\n",
    "        temp_dict = dict(zip(temp_df['index'], temp_df[0]))\n",
    "        meta_fil_dict[col] = temp_dict\n",
    "        \n",
    "return_meta_fil_dict = {}\n",
    "return_meta_fil_dict['sentence'] = meta_fil_dict\n",
    "\n",
    "# By Document files\n",
    "meta_df = meta_df.groupby('file_name').first().reset_index()\n",
    "min_count = 0\n",
    "fil_col_list = ['central_bank', 'keyword']\n",
    "meta_fil_dict = {}\n",
    "for col in fil_col_list:\n",
    "    if col in alt_col_list and col in list(meta_df.columns):\n",
    "        temp_df = pd.DataFrame(flatten(list(meta_df[col].values)))[0].value_counts().reset_index()\n",
    "    elif col in main_col_list and col in list(meta_df.columns):\n",
    "        temp_df = pd.DataFrame(list(meta_df[col].values))[0].value_counts().reset_index()\n",
    "    \n",
    "    if col in list(meta_df.columns):\n",
    "        temp_df = temp_df[temp_df[0] >= min_count]\n",
    "        temp_dict = dict(zip(temp_df['index'], temp_df[0]))\n",
    "        meta_fil_dict[col] = temp_dict\n",
    "        \n",
    "return_meta_fil_dict['document'] = meta_fil_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "992e553e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever_pipe = DocumentSearchPipeline(retriever)\n",
    "# reader_pipe = ExtractiveQAPipeline(reader,retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d195fc8",
   "metadata": {},
   "source": [
    "# Set API Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8df651c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK !\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/haystack_200_reader_pipe', methods=['POST'])\n",
    "def haystack_200_reader_pipe():\n",
    "    query_list = []\n",
    "    if request.method == 'POST':\n",
    "        body = request.get_json()\n",
    "        if body['retriever_type'] == 'Exact Match':\n",
    "            reader_pipe = ExtractiveQAPipeline(random.choice(reader_list), tfidf_retriever)\n",
    "        elif body['retriever_type'] == 'Semantic Search (DPR)':\n",
    "            reader_pipe = ExtractiveQAPipeline(random.choice(reader_list), dpr_retriever)\n",
    "        elif body['retriever_type'] == 'Semantic Search (ER)':\n",
    "            reader_pipe = ExtractiveQAPipeline(random.choice(reader_list), er_retriever)\n",
    "            \n",
    "        prediction = reader_pipe.run(\n",
    "            query=body['query'], params={\"Retriever\": {\"top_k\": int(body['top_k_retriever'])},\n",
    "                                         \"Reader\": {'top_k': int(body['top_k_reader'])},\n",
    "                                         \"filters\": body['filters'],\n",
    "                                         }\n",
    "        )\n",
    "        ans_dict = prediction['answers']\n",
    "        ans_dict = [each.__dict__ for each in ans_dict]\n",
    "        prediction['answers'] = ans_dict\n",
    "        doc_dict = prediction['documents']\n",
    "        doc_dict = [each.__dict__ for each in doc_dict]\n",
    "        prediction['documents'] = doc_dict\n",
    "        \n",
    "        return prediction, 201\n",
    "    \n",
    "@app.route('/haystack_200_retriever_pipe', methods=['POST'])\n",
    "def haystack_200_retriever_pipe():\n",
    "    query_list = []\n",
    "    if request.method == 'POST':\n",
    "        body = request.get_json()\n",
    "        if body['retriever_type'] == 'Exact Match':\n",
    "            retriever_pipe = DocumentSearchPipeline(tfidf_retriever)\n",
    "        elif body['retriever_type'] == 'Semantic Search (DPR)':\n",
    "            retriever_pipe = DocumentSearchPipeline(dpr_retriever)\n",
    "        elif body['retriever_type'] == 'Semantic Search (ER)':\n",
    "            retriever_pipe = DocumentSearchPipeline(er_retriever)\n",
    "        prediction = retriever_pipe.run(\n",
    "            query=body['query'], params={\"Retriever\": {\"top_k\": int(body['top_k_retriever'])},\n",
    "                                         \"filters\": body['filters'],\n",
    "                                         }\n",
    "        )\n",
    "        \n",
    "        doc_list = [each.__dict__ for each in prediction['documents']]\n",
    "        prediction['documents'] = doc_list\n",
    "        return prediction, 201\n",
    "    \n",
    "@app.route('/haystack_200_meta', methods=['GET'])\n",
    "def haystack_200_meta():\n",
    "    query_list = []\n",
    "    if request.method == 'GET':        \n",
    "        return return_meta_fil_dict, 201\n",
    "    \n",
    "print('OK !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dde2e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - werkzeug -   * Running on http://127.0.0.1:5201 (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "app.run(port = 5201)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1746fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf06ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global_2b_ria",
   "language": "python",
   "name": "global_2b_ria"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
