{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "890431d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK !\n"
     ]
    }
   ],
   "source": [
    "#Default\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:,}'.format\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "def reset(df):\n",
    "    cols = df.columns\n",
    "    return df.reset_index()[cols]\n",
    "def print_counts(df):\n",
    "    cols = df.columns\n",
    "    for each in cols:\n",
    "        print(each)\n",
    "        print(df[each].value_counts())\n",
    "        print('______________________________________')\n",
    "        \n",
    "def flatten(list_1):\n",
    "    list_2 = []\n",
    "    for each in list(list_1):\n",
    "        try:\n",
    "            for each_2 in each:\n",
    "                list_2.append(each_2)\n",
    "        except:\n",
    "            pass\n",
    "    return list_2\n",
    "        \n",
    "# ~\n",
    "#Default Ending\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "print('OK !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d01f83c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.base -  Numba not found, replacing njit() with no-op implementation. Enable it with 'pip install numba'.\n",
      "INFO - haystack.modeling.model.optimization -  apex not found, won't use it. See https://nvidia.github.io/apex/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK !\n"
     ]
    }
   ],
   "source": [
    "from haystack.utils import clean_wiki_text, convert_files_to_dicts, fetch_archive_from_http, print_answers\n",
    "from haystack.nodes import DensePassageRetriever, EmbeddingRetriever, FARMReader, EntityExtractor, TfidfRetriever, ElasticsearchRetriever\n",
    "from haystack.document_stores import ElasticsearchDocumentStore\n",
    "from haystack.pipelines import ExtractiveQAPipeline, DocumentSearchPipeline\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "print('OK !')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5656cf0",
   "metadata": {},
   "source": [
    "# Embedding Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1ed70ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For EmbeddingRetriever\n",
    "similarity_type = \"cosine\"\n",
    "\n",
    "container_name = \"es1\"\n",
    "\n",
    "er_100 = ElasticsearchDocumentStore(host=container_name, port = \"9200\", index=\"production_er_100\",\n",
    "                                           similarity=similarity_type, embedding_dim=768)\n",
    "er_200 = ElasticsearchDocumentStore(host=container_name, port = \"9200\", index=\"production_er_200\",\n",
    "                                           similarity=similarity_type, embedding_dim=768)\n",
    "er_300 = ElasticsearchDocumentStore(host=container_name, port = \"9200\", index=\"production_er_300\",\n",
    "                                           similarity=similarity_type, embedding_dim=768)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7958aa03",
   "metadata": {},
   "source": [
    "# Dense Passage Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "562bf40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For DensePassageRetriever\n",
    "similarity_type = \"dot_product\"\n",
    "\n",
    "dpr_100 = ElasticsearchDocumentStore(host=container_name, port = \"9200\", index=\"production_dpr_100\",\n",
    "                                           similarity=similarity_type)\n",
    "dpr_200 = ElasticsearchDocumentStore(host=container_name, port = \"9200\", index=\"production_dpr_200\",\n",
    "                                           similarity=similarity_type)\n",
    "dpr_300 = ElasticsearchDocumentStore(host=container_name, port = \"9200\", index=\"production_dpr_300\",\n",
    "                                           similarity=similarity_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f604e32e",
   "metadata": {},
   "source": [
    "# 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df49f3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.nodes.base -  Unnamed __init__ parameters will not be saved to YAML if Pipeline.save_to_yaml() is called!\n",
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0, CUDA:1\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 2\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at ../shared_data/thanatcc/RIA_Model/DPR-retriever/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded ../shared_data/thanatcc/RIA_Model/DPR-retriever/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at ../shared_data/thanatcc/RIA_Model/DPR-retriever/passage_encoder\n",
      "INFO - backoff -  Backing off send_request(...) for 0.0s (requests.exceptions.SSLError: HTTPSConnectionPool(host='tm.hs.deepset.ai', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)'))))\n",
      "INFO - haystack.modeling.model.language_model -  Loaded ../shared_data/thanatcc/RIA_Model/DPR-retriever/passage_encoder\n",
      "INFO - backoff -  Backing off send_request(...) for 0.9s (requests.exceptions.SSLError: HTTPSConnectionPool(host='tm.hs.deepset.ai', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)'))))\n",
      "INFO - backoff -  Backing off send_request(...) for 0.4s (requests.exceptions.SSLError: HTTPSConnectionPool(host='tm.hs.deepset.ai', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)'))))\n",
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0, CUDA:1\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 2\n",
      "INFO - haystack.nodes.retriever.dense -  Init retriever using embeddings of model ../shared_data/thanatcc/RIA_Model/all-mpnet-base-v1\n"
     ]
    }
   ],
   "source": [
    "bm25_retriever_100 = ElasticsearchRetriever(er_100)\n",
    "\n",
    "dpr_retriever_100 = DensePassageRetriever(\n",
    "    document_store=dpr_100,\n",
    "    query_embedding_model=\"../shared_data/thanatcc/RIA_Model/DPR-retriever/query_encoder\",\n",
    "    passage_embedding_model=\"../shared_data/thanatcc/RIA_Model/DPR-retriever/passage_encoder\",\n",
    "    max_seq_len_query=64,\n",
    "    max_seq_len_passage=256,\n",
    "    batch_size=16,\n",
    "    use_gpu=True,\n",
    "    embed_title=True,\n",
    "    use_fast_tokenizers=True,\n",
    ")\n",
    "\n",
    "er_retriever_100 = EmbeddingRetriever(\n",
    "   document_store=er_100,\n",
    "   embedding_model=\"../shared_data/thanatcc/RIA_Model/all-mpnet-base-v1\",\n",
    "   model_format=\"sentence_transformers\",\n",
    "   use_gpu = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1650770d",
   "metadata": {},
   "source": [
    "# 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fa4d888",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.nodes.base -  Unnamed __init__ parameters will not be saved to YAML if Pipeline.save_to_yaml() is called!\n",
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0, CUDA:1\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 2\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at ../shared_data/thanatcc/RIA_Model/DPR-retriever/query_encoder\n",
      "ERROR - backoff -  Giving up send_request(...) after 4 tries (requests.exceptions.SSLError: HTTPSConnectionPool(host='tm.hs.deepset.ai', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)'))))\n",
      "ERROR - posthog -  error uploading: HTTPSConnectionPool(host='tm.hs.deepset.ai', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)')))\n",
      "INFO - haystack.modeling.model.language_model -  Loaded ../shared_data/thanatcc/RIA_Model/DPR-retriever/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at ../shared_data/thanatcc/RIA_Model/DPR-retriever/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded ../shared_data/thanatcc/RIA_Model/DPR-retriever/passage_encoder\n",
      "INFO - backoff -  Backing off send_request(...) for 0.3s (requests.exceptions.SSLError: HTTPSConnectionPool(host='tm.hs.deepset.ai', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)'))))\n",
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0, CUDA:1\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 2\n",
      "INFO - haystack.nodes.retriever.dense -  Init retriever using embeddings of model ../shared_data/thanatcc/RIA_Model/all-mpnet-base-v1\n"
     ]
    }
   ],
   "source": [
    "bm25_retriever_200 = ElasticsearchRetriever(er_200)\n",
    "\n",
    "dpr_retriever_200 = DensePassageRetriever(\n",
    "    document_store=dpr_200,\n",
    "    query_embedding_model=\"../shared_data/thanatcc/RIA_Model/DPR-retriever/query_encoder\",\n",
    "    passage_embedding_model=\"../shared_data/thanatcc/RIA_Model/DPR-retriever/passage_encoder\",\n",
    "    max_seq_len_query=64,\n",
    "    max_seq_len_passage=256,\n",
    "    batch_size=16,\n",
    "    use_gpu=True,\n",
    "    embed_title=True,\n",
    "    use_fast_tokenizers=True,\n",
    ")\n",
    "\n",
    "er_retriever_200 = EmbeddingRetriever(\n",
    "   document_store=er_200,\n",
    "   embedding_model=\"../shared_data/thanatcc/RIA_Model/all-mpnet-base-v1\",\n",
    "   model_format=\"sentence_transformers\",\n",
    "   use_gpu = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d31b05",
   "metadata": {},
   "source": [
    "# 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bc398b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.nodes.base -  Unnamed __init__ parameters will not be saved to YAML if Pipeline.save_to_yaml() is called!\n",
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0, CUDA:1\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 2\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at ../shared_data/thanatcc/RIA_Model/DPR-retriever/query_encoder\n",
      "INFO - backoff -  Backing off send_request(...) for 0.2s (requests.exceptions.SSLError: HTTPSConnectionPool(host='tm.hs.deepset.ai', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)'))))\n",
      "INFO - haystack.modeling.model.language_model -  Loaded ../shared_data/thanatcc/RIA_Model/DPR-retriever/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at ../shared_data/thanatcc/RIA_Model/DPR-retriever/passage_encoder\n",
      "INFO - backoff -  Backing off send_request(...) for 1.9s (requests.exceptions.SSLError: HTTPSConnectionPool(host='tm.hs.deepset.ai', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)'))))\n",
      "INFO - haystack.modeling.model.language_model -  Loaded ../shared_data/thanatcc/RIA_Model/DPR-retriever/passage_encoder\n",
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0, CUDA:1\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 2\n",
      "INFO - haystack.nodes.retriever.dense -  Init retriever using embeddings of model ../shared_data/thanatcc/RIA_Model/all-mpnet-base-v1\n"
     ]
    }
   ],
   "source": [
    "bm25_retriever_300 = ElasticsearchRetriever(er_300)\n",
    "\n",
    "dpr_retriever_300 = DensePassageRetriever(\n",
    "    document_store=dpr_300,\n",
    "    query_embedding_model=\"../shared_data/thanatcc/RIA_Model/DPR-retriever/query_encoder\",\n",
    "    passage_embedding_model=\"../shared_data/thanatcc/RIA_Model/DPR-retriever/passage_encoder\",\n",
    "    max_seq_len_query=64,\n",
    "    max_seq_len_passage=256,\n",
    "    batch_size=16,\n",
    "    use_gpu=True,\n",
    "    embed_title=True,\n",
    "    use_fast_tokenizers=True,\n",
    ")\n",
    "\n",
    "er_retriever_300 = EmbeddingRetriever(\n",
    "   document_store=er_300,\n",
    "   embedding_model=\"../shared_data/thanatcc/RIA_Model/all-mpnet-base-v1\",\n",
    "   model_format=\"sentence_transformers\",\n",
    "   use_gpu = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77f96b9",
   "metadata": {},
   "source": [
    "# Set Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a94033cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at ../shared_data/thanatcc/RIA_Model/roberta-base-squad2-reader\n",
      "INFO - haystack.modeling.model.language_model -  Loaded ../shared_data/thanatcc/RIA_Model/roberta-base-squad2-reader\n",
      "INFO - haystack.modeling.model.adaptive_model -  Found files for loading 1 prediction heads\n",
      "WARNING - haystack.modeling.model.prediction_head -  Some unused parameters are passed to the QuestionAnsweringHead. Might not be a problem. Params: {\"training\": false, \"num_labels\": 2, \"ph_output_type\": \"per_token_squad\", \"model_type\": \"span_classification\", \"label_tensor_name\": \"question_answering_label_ids\", \"label_list\": [\"start_token\", \"end_token\"], \"metric\": \"squad\", \"name\": \"QuestionAnsweringHead\"}\n",
      "INFO - haystack.modeling.model.prediction_head -  Loading prediction head from ../shared_data/thanatcc/RIA_Model/roberta-base-squad2-reader/prediction_head_0.bin\n",
      "WARNING - haystack.modeling.logger -  Failed to log params: Changing param values is not allowed. Param with key='prediction_heads' was already logged with value='TextSimilarityHead' for run ID='655fb44cddc74a8d932c99b3c9e29abf'. Attempted logging new value 'QuestionAnsweringHead'.\n",
      "WARNING - haystack.modeling.logger -  Failed to log params: Changing param values is not allowed. Param with key='processor' was already logged with value='TextSimilarityProcessor' for run ID='655fb44cddc74a8d932c99b3c9e29abf'. Attempted logging new value 'SquadProcessor'.\n",
      "INFO - haystack.modeling.data_handler.processor -  Initialized processor without tasks. Supply `metric` and `label_list` to the constructor for using the default task or add a custom task later via processor.add_task()\n",
      "INFO - haystack.modeling.logger -  ML Logging is turned off. No parameters, metrics or artifacts will be logged to MLFlow.\n",
      "INFO - haystack.modeling.utils -  Using devices: CUDA\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.infer -  Got ya 7 parallel workers to do inference ...\n",
      "INFO - haystack.modeling.infer -   0     0     0     0     0     0     0  \n",
      "INFO - haystack.modeling.infer -  /w\\   /w\\   /w\\   /w\\   /w\\   /w\\   /w\\ \n",
      "INFO - haystack.modeling.infer -  /'\\   / \\   /'\\   /'\\   / \\   / \\   /'\\ \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<haystack.nodes.reader.farm.FARMReader at 0x7ff461213df0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<haystack.nodes.reader.farm.FARMReader at 0x7ff461213df0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reader_path = \"../shared_data/thanatcc/RIA_Model/albert_xxlargev1_squad2_512-reader\"\n",
    "reader_path = \"../shared_data/thanatcc/RIA_Model/roberta-base-squad2-reader\"\n",
    "reader_1 = FARMReader(model_name_or_path=reader_path, \n",
    "                      use_gpu=1)\n",
    "\n",
    "# reader_list = [reader_1, reader_2]\n",
    "reader_list = [reader_1]\n",
    "reader_list\n",
    "\n",
    "random.choice(reader_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be65bb9e",
   "metadata": {},
   "source": [
    "# Collocations & Question Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39d3c231",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR - backoff -  Giving up send_request(...) after 4 tries (requests.exceptions.SSLError: HTTPSConnectionPool(host='tm.hs.deepset.ai', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)'))))\n",
      "ERROR - posthog -  error uploading: HTTPSConnectionPool(host='tm.hs.deepset.ai', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)')))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a title']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from itertools import combinations\n",
    "\n",
    "# Set globals\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "def pre_process(titles):\n",
    "    \"\"\"\n",
    "    Pre-processes titles by removing stopwords and lemmatizing text.\n",
    "    :param titles: list of strings, contains target titles,.\n",
    "    :return: preprocessed_title_docs, list containing pre-processed titles.\n",
    "    \"\"\"\n",
    "\n",
    "    # Preprocess all the titles\n",
    "    title_docs = [nlp(x) for x in titles]\n",
    "    preprocessed_title_docs = []\n",
    "    lemmatized_tokens = []\n",
    "    for title_doc in title_docs:\n",
    "        for token in title_doc:\n",
    "            if not token.is_stop:\n",
    "                lemmatized_tokens.append(token.lemma_)\n",
    "        preprocessed_title_docs.append(\" \".join(lemmatized_tokens))\n",
    "        del lemmatized_tokens[\n",
    "            :\n",
    "            ]  # empty the lemmatized tokens list as the code moves onto a new title\n",
    "\n",
    "    return preprocessed_title_docs\n",
    "\n",
    "def similarity_filter(titles):\n",
    "    \"\"\"\n",
    "    Recursively check if titles pass a similarity filter.\n",
    "    :param titles: list of strings, contains titles.\n",
    "    If the function finds titles that fail the similarity test, the above param will be the function output.\n",
    "    :return: this method upon itself unless there are no similar titles; in that case the feed that was passed\n",
    "    in is returned.\n",
    "    \"\"\"\n",
    "\n",
    "    # Preprocess titles\n",
    "    preprocessed_title_docs = pre_process(titles)\n",
    "\n",
    "    # Remove similar titles\n",
    "    all_summary_pairs = list(combinations(preprocessed_title_docs, 2))\n",
    "    similar_titles = []\n",
    "    for pair in all_summary_pairs:\n",
    "        title1 = nlp(pair[0])\n",
    "        title2 = nlp(pair[1])\n",
    "        similarity = title1.similarity(title2)\n",
    "        if similarity > 0.8:\n",
    "            similar_titles.append(pair)\n",
    "\n",
    "    titles_to_remove = []\n",
    "    for a_title in similar_titles:\n",
    "        # Get the index of the first title in the pair\n",
    "        index_for_removal = preprocessed_title_docs.index(a_title[0])\n",
    "        titles_to_remove.append(index_for_removal)\n",
    "\n",
    "    # Get indices of similar titles and remove them\n",
    "    similar_title_counts = set(titles_to_remove)\n",
    "    similar_titles = [\n",
    "        x[1] for x in enumerate(titles) if x[0] in similar_title_counts\n",
    "    ]\n",
    "\n",
    "    # Exit the recursion if there are no longer any similar titles\n",
    "    if len(similar_title_counts) == 0:\n",
    "        return titles\n",
    "\n",
    "    # Continue the recursion if there are still titles to remove\n",
    "    else:\n",
    "        # Remove similar titles from the next input\n",
    "        for title in similar_titles:\n",
    "            idx = titles.index(title)\n",
    "            titles.pop(idx)\n",
    "            \n",
    "        return similarity_filter(titles)\n",
    "    \n",
    "def get_distinct_similarity_filter(list_1, num = 9):\n",
    "    try:\n",
    "        return_list = []\n",
    "        return_list.append(list_1[0])\n",
    "        for i, each in enumerate(list_1):\n",
    "            dis_list = similarity_filter([list_1[i], list_1[i+1]])\n",
    "            if len(dis_list) == 2:\n",
    "                return_list.append(dis_list[-1])\n",
    "            if len(return_list) == num:\n",
    "                break\n",
    "    except:\n",
    "        pass\n",
    "    return return_list\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    your_title_list = ['a title', 'the title']\n",
    "    get_distinct_similarity_filter(your_title_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a14b04d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For EmbeddingRetriever\n",
    "similarity_type = \"cosine\"\n",
    "\n",
    "container_name = \"es1\"\n",
    "\n",
    "er_co = ElasticsearchDocumentStore(host=container_name, port = \"9200\", index=\"production_er_bigram_collocation\",\n",
    "                                           similarity=similarity_type, embedding_dim=768)\n",
    "\n",
    "er_qg = ElasticsearchDocumentStore(host=container_name, port = \"9200\", index=\"production_er_question_generation\",\n",
    "                                           similarity=similarity_type, embedding_dim=768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d73302d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0, CUDA:1\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 2\n",
      "INFO - haystack.nodes.retriever.dense -  Init retriever using embeddings of model ../shared_data/thanatcc/RIA_Model/all-mpnet-base-v1\n",
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0, CUDA:1\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 2\n",
      "INFO - haystack.nodes.retriever.dense -  Init retriever using embeddings of model ../shared_data/thanatcc/RIA_Model/all-mpnet-base-v1\n",
      "INFO - backoff -  Backing off send_request(...) for 0.0s (requests.exceptions.SSLError: HTTPSConnectionPool(host='tm.hs.deepset.ai', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)'))))\n"
     ]
    }
   ],
   "source": [
    "co_retriever = EmbeddingRetriever(\n",
    "   document_store=er_co,\n",
    "   embedding_model=\"../shared_data/thanatcc/RIA_Model/all-mpnet-base-v1\",\n",
    "   model_format=\"sentence_transformers\",\n",
    "   use_gpu = True,\n",
    ")\n",
    "\n",
    "qg_retriever = EmbeddingRetriever(\n",
    "   document_store=er_qg,\n",
    "   embedding_model=\"../shared_data/thanatcc/RIA_Model/all-mpnet-base-v1\",\n",
    "   model_format=\"sentence_transformers\",\n",
    "   use_gpu = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d195fc8",
   "metadata": {},
   "source": [
    "# Set API Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e4ca6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK !\n"
     ]
    }
   ],
   "source": [
    "def process_reader_pipe(bm25_retriever, dpr_retriever, er_retriever, body):\n",
    "    if body['retriever_type'] == 'Exact Match':\n",
    "        reader_pipe = ExtractiveQAPipeline(random.choice(reader_list), bm25_retriever)\n",
    "    elif body['retriever_type'] == 'Semantic Search (DPR)':\n",
    "        reader_pipe = ExtractiveQAPipeline(random.choice(reader_list), dpr_retriever)\n",
    "    elif body['retriever_type'] == 'Semantic Search (ER)':\n",
    "        reader_pipe = ExtractiveQAPipeline(random.choice(reader_list), er_retriever)\n",
    "\n",
    "    prediction = reader_pipe.run(\n",
    "        query=body['query'], params={\"Retriever\": {\"top_k\": int(body['top_k_retriever'])},\n",
    "                                     \"Reader\": {'top_k': int(body['top_k_reader'])},\n",
    "                                     \"filters\": body['filters'],\n",
    "                                     }\n",
    "    )\n",
    "    ans_dict = prediction['answers']\n",
    "    ans_dict = [each.__dict__ for each in ans_dict]\n",
    "    prediction['answers'] = ans_dict\n",
    "    doc_dict = prediction['documents']\n",
    "    doc_dict = [each.__dict__ for each in doc_dict]\n",
    "    prediction['documents'] = doc_dict\n",
    "    return prediction\n",
    "\n",
    "def process_retriever_pipe(bm25_retriever, dpr_retriever, er_retriever, body):\n",
    "    if body['retriever_type'] == 'Exact Match':\n",
    "        retriever_pipe = DocumentSearchPipeline(bm25_retriever)\n",
    "    elif body['retriever_type'] == 'Semantic Search (DPR)':\n",
    "        retriever_pipe = DocumentSearchPipeline(dpr_retriever)\n",
    "    elif body['retriever_type'] == 'Semantic Search (ER)':\n",
    "        retriever_pipe = DocumentSearchPipeline(er_retriever)\n",
    "    prediction = retriever_pipe.run(\n",
    "        query=body['query'], params={\"Retriever\": {\"top_k\": int(body['top_k_retriever'])},\n",
    "                                     \"filters\": body['filters'],\n",
    "                                     }\n",
    "    )\n",
    "    doc_list = [each.__dict__ for each in prediction['documents']]\n",
    "    prediction['documents'] = doc_list\n",
    "    return prediction\n",
    "\n",
    "def process_suggestions(retriever, body):\n",
    "    retriever_pipe = DocumentSearchPipeline(retriever)\n",
    "    prediction = retriever_pipe.run(\n",
    "        query=body['query'], params={\"Retriever\": {\"top_k\": 100},\n",
    "                                     \"filters\": body['filters'],\n",
    "                                     }\n",
    "    )\n",
    "    doc_list = [each.__dict__ for each in prediction['documents']]\n",
    "    prediction['documents'] = doc_list\n",
    "    suggested_co_list = prediction['documents']\n",
    "    suggested_co_list = [each['content'] for each in suggested_co_list]\n",
    "    return suggested_co_list\n",
    "\n",
    "print('OK !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8df651c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - backoff -  Backing off send_request(...) for 0.6s (requests.exceptions.SSLError: HTTPSConnectionPool(host='tm.hs.deepset.ai', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)'))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK !\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/haystack_100_reader_pipe', methods=['POST'])\n",
    "def haystack_100_reader_pipe():\n",
    "    if request.method == 'POST':\n",
    "        body = request.get_json()\n",
    "        prediction = process_reader_pipe(bm25_retriever_100, dpr_retriever_100, er_retriever_100, body)\n",
    "        return prediction, 201\n",
    "    \n",
    "@app.route('/haystack_200_reader_pipe', methods=['POST'])\n",
    "def haystack_200_reader_pipe():\n",
    "    if request.method == 'POST':\n",
    "        body = request.get_json()\n",
    "        prediction = process_reader_pipe(bm25_retriever_200, dpr_retriever_200, er_retriever_200, body)\n",
    "        return prediction, 201\n",
    "    \n",
    "@app.route('/haystack_300_reader_pipe', methods=['POST'])\n",
    "def haystack_300_reader_pipe():\n",
    "    if request.method == 'POST':\n",
    "        body = request.get_json()\n",
    "        prediction = process_reader_pipe(bm25_retriever_300, dpr_retriever_300, er_retriever_300, body)\n",
    "        return prediction, 201\n",
    "    \n",
    "@app.route('/haystack_100_retriever_pipe', methods=['POST'])\n",
    "def haystack_100_retriever_pipe():\n",
    "    if request.method == 'POST':\n",
    "        body = request.get_json()\n",
    "        prediction = process_retriever_pipe(bm25_retriever_100, dpr_retriever_100, er_retriever_100, body)\n",
    "        return prediction, 201\n",
    "    \n",
    "@app.route('/haystack_200_retriever_pipe', methods=['POST'])\n",
    "def haystack_200_retriever_pipe():\n",
    "    if request.method == 'POST':\n",
    "        body = request.get_json()\n",
    "        prediction = process_retriever_pipe(bm25_retriever_200, dpr_retriever_200, er_retriever_200, body)\n",
    "        return prediction, 201\n",
    "    \n",
    "@app.route('/haystack_300_retriever_pipe', methods=['POST'])\n",
    "def haystack_300_retriever_pipe():\n",
    "    if request.method == 'POST':\n",
    "        body = request.get_json()\n",
    "        prediction = process_retriever_pipe(bm25_retriever_300, dpr_retriever_300, er_retriever_300, body)\n",
    "        return prediction, 201\n",
    "    \n",
    "@app.route('/haystack_collocation', methods=['POST'])\n",
    "def haystack_collocation():\n",
    "    if request.method == 'POST':\n",
    "        body = request.get_json()\n",
    "        suggested_co_list = process_suggestions(co_retriever, body)\n",
    "        suggested_co_list = get_distinct_similarity_filter(suggested_co_list)[1:]\n",
    "        return {'suggested_keywords': suggested_co_list}, 201\n",
    "    \n",
    "@app.route('/haystack_question_generation', methods=['POST'])\n",
    "def haystack_question_generation():\n",
    "    if request.method == 'POST':\n",
    "        body = request.get_json()\n",
    "        suggested_co_list = process_suggestions(qg_retriever, body)\n",
    "        suggested_co_list = [each for each in suggested_co_list if len(word_tokenize(each)) >= 8]\n",
    "        suggested_co_list = get_distinct_similarity_filter(suggested_co_list)[1:]\n",
    "        return {'suggested_keywords': suggested_co_list}, 201\n",
    "        \n",
    "print('OK !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dde2e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - werkzeug -   * Running on http://127.0.0.1:5101 (Press CTRL+C to quit)\n",
      "INFO - backoff -  Backing off send_request(...) for 0.9s (requests.exceptions.SSLError: HTTPSConnectionPool(host='tm.hs.deepset.ai', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)'))))\n",
      "ERROR - backoff -  Giving up send_request(...) after 4 tries (requests.exceptions.SSLError: HTTPSConnectionPool(host='tm.hs.deepset.ai', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)'))))\n",
      "ERROR - posthog -  error uploading: HTTPSConnectionPool(host='tm.hs.deepset.ai', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)')))\n",
      "INFO - backoff -  Backing off send_request(...) for 0.7s (requests.exceptions.SSLError: HTTPSConnectionPool(host='tm.hs.deepset.ai', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)'))))\n",
      "INFO - backoff -  Backing off send_request(...) for 1.4s (requests.exceptions.SSLError: HTTPSConnectionPool(host='tm.hs.deepset.ai', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)'))))\n",
      "INFO - backoff -  Backing off send_request(...) for 3.6s (requests.exceptions.SSLError: HTTPSConnectionPool(host='tm.hs.deepset.ai', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)'))))\n"
     ]
    }
   ],
   "source": [
    "app.run(port = 5101)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "production_2b_ria",
   "language": "python",
   "name": "production_2b_ria"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
