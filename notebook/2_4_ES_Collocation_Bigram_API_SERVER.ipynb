{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890431d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Default\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:,}'.format\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "def reset(df):\n",
    "    cols = df.columns\n",
    "    return df.reset_index()[cols]\n",
    "def print_counts(df):\n",
    "    cols = df.columns\n",
    "    for each in cols:\n",
    "        print(each)\n",
    "        print(df[each].value_counts())\n",
    "        print('______________________________________')\n",
    "# ~\n",
    "#Default Ending\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "print('OK !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01f83c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.utils import clean_wiki_text, convert_files_to_dicts, fetch_archive_from_http, print_answers\n",
    "from haystack.nodes import DensePassageRetriever, EmbeddingRetriever, FARMReader, EntityExtractor\n",
    "from haystack.document_stores import ElasticsearchDocumentStore\n",
    "\n",
    "import torch\n",
    "\n",
    "print('OK !')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5656cf0",
   "metadata": {},
   "source": [
    "# Embedding Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409ddfad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For EmbeddingRetriever\n",
    "similarity_type = \"cosine\"\n",
    "\n",
    "container_name = \"localhost\"\n",
    "\n",
    "er_co = ElasticsearchDocumentStore(host=container_name, port = \"9200\", index=\"production_er_bigram_collocation\",\n",
    "                                           similarity=similarity_type, embedding_dim=768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25186bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.nodes import TextConverter, PDFToTextConverter, DocxToTextConverter, PreProcessor\n",
    "\n",
    "converter = PDFToTextConverter(remove_numeric_tables=False, valid_languages = [\"en\"])\n",
    "\n",
    "print('OK !')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f604e32e",
   "metadata": {},
   "source": [
    "# Set document_store "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca25b07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store = er_co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9a0b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from itertools import combinations\n",
    "\n",
    "# Set globals\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "def pre_process(titles):\n",
    "    \"\"\"\n",
    "    Pre-processes titles by removing stopwords and lemmatizing text.\n",
    "    :param titles: list of strings, contains target titles,.\n",
    "    :return: preprocessed_title_docs, list containing pre-processed titles.\n",
    "    \"\"\"\n",
    "\n",
    "    # Preprocess all the titles\n",
    "    title_docs = [nlp(x) for x in titles]\n",
    "    preprocessed_title_docs = []\n",
    "    lemmatized_tokens = []\n",
    "    for title_doc in title_docs:\n",
    "        for token in title_doc:\n",
    "            if not token.is_stop:\n",
    "                lemmatized_tokens.append(token.lemma_)\n",
    "        preprocessed_title_docs.append(\" \".join(lemmatized_tokens))\n",
    "        del lemmatized_tokens[\n",
    "            :\n",
    "            ]  # empty the lemmatized tokens list as the code moves onto a new title\n",
    "\n",
    "    return preprocessed_title_docs\n",
    "\n",
    "def similarity_filter(titles):\n",
    "    \"\"\"\n",
    "    Recursively check if titles pass a similarity filter.\n",
    "    :param titles: list of strings, contains titles.\n",
    "    If the function finds titles that fail the similarity test, the above param will be the function output.\n",
    "    :return: this method upon itself unless there are no similar titles; in that case the feed that was passed\n",
    "    in is returned.\n",
    "    \"\"\"\n",
    "\n",
    "    # Preprocess titles\n",
    "    preprocessed_title_docs = pre_process(titles)\n",
    "\n",
    "    # Remove similar titles\n",
    "    all_summary_pairs = list(combinations(preprocessed_title_docs, 2))\n",
    "    similar_titles = []\n",
    "    for pair in all_summary_pairs:\n",
    "        title1 = nlp(pair[0])\n",
    "        title2 = nlp(pair[1])\n",
    "        similarity = title1.similarity(title2)\n",
    "        if similarity > 0.8:\n",
    "            similar_titles.append(pair)\n",
    "\n",
    "    titles_to_remove = []\n",
    "    for a_title in similar_titles:\n",
    "        # Get the index of the first title in the pair\n",
    "        index_for_removal = preprocessed_title_docs.index(a_title[0])\n",
    "        titles_to_remove.append(index_for_removal)\n",
    "\n",
    "    # Get indices of similar titles and remove them\n",
    "    similar_title_counts = set(titles_to_remove)\n",
    "    similar_titles = [\n",
    "        x[1] for x in enumerate(titles) if x[0] in similar_title_counts\n",
    "    ]\n",
    "\n",
    "    # Exit the recursion if there are no longer any similar titles\n",
    "    if len(similar_title_counts) == 0:\n",
    "        return titles\n",
    "\n",
    "    # Continue the recursion if there are still titles to remove\n",
    "    else:\n",
    "        # Remove similar titles from the next input\n",
    "        for title in similar_titles:\n",
    "            idx = titles.index(title)\n",
    "            titles.pop(idx)\n",
    "            \n",
    "        return similarity_filter(titles)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    your_title_list = ['a title', 'the title']\n",
    "    similarity_filter(your_title_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5bec44",
   "metadata": {},
   "outputs": [],
   "source": [
    "er_retriever = EmbeddingRetriever(\n",
    "   document_store=document_store,\n",
    "   embedding_model=\"all-mpnet-base-v1\",\n",
    "   model_format=\"sentence_transformers\",\n",
    "   use_gpu = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3336ef0d",
   "metadata": {},
   "source": [
    "# Set API Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55024ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from haystack.pipelines import DocumentSearchPipeline\n",
    "\n",
    "print('OK !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03038237",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/haystack_collocation', methods=['POST'])\n",
    "def haystack_collocation():\n",
    "    query_list = []\n",
    "    if request.method == 'POST':\n",
    "        body = request.get_json()\n",
    "        retriever_pipe = DocumentSearchPipeline(er_retriever)\n",
    "        prediction = retriever_pipe.run(\n",
    "            query=body['query'], params={\"Retriever\": {\"top_k\": 24},\n",
    "                                         \"filters\": body['filters'],\n",
    "                                         }\n",
    "        )\n",
    "        \n",
    "        doc_list = [each.__dict__ for each in prediction['documents']]\n",
    "        prediction['documents'] = doc_list\n",
    "        suggested_co_list = prediction['documents']\n",
    "        suggested_co_list = [each['content'] for each in suggested_co_list]\n",
    "        suggested_co_list = similarity_filter(suggested_co_list)\n",
    "        return {'suggested_keywords': suggested_co_list}, 201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e219256",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.run(port = 7101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223dd199",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py38hay]",
   "language": "python",
   "name": "conda-env-py38hay-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
