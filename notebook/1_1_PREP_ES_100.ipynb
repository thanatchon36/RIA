{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "890431d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK !\n"
     ]
    }
   ],
   "source": [
    "#Default\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:,}'.format\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "def reset(df):\n",
    "    cols = df.columns\n",
    "    return df.reset_index()[cols]\n",
    "def print_counts(df):\n",
    "    cols = df.columns\n",
    "    for each in cols:\n",
    "        print(each)\n",
    "        print(df[each].value_counts())\n",
    "        print('______________________________________')\n",
    "# ~\n",
    "#Default Ending\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "print('OK !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d01f83c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.model.optimization -  apex not found, won't use it. See https://nvidia.github.io/apex/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK !\n"
     ]
    }
   ],
   "source": [
    "from haystack.utils import clean_wiki_text, convert_files_to_dicts, fetch_archive_from_http, print_answers\n",
    "from haystack.nodes import DensePassageRetriever, EmbeddingRetriever, FARMReader, EntityExtractor\n",
    "from haystack.document_stores import ElasticsearchDocumentStore\n",
    "\n",
    "print('OK !')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5656cf0",
   "metadata": {},
   "source": [
    "# Set similarity_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1ed70ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For DensePassageRetriever\n",
    "similarity_type = \"dot_product\"\n",
    "\n",
    "# For EmbeddingRetriever\n",
    "# similarity_type = \"cosine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "409ddfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store_100 = ElasticsearchDocumentStore(host=\"localhost\", port = \"9200\", index=\"document_100\",\n",
    "                                           similarity=similarity_type)\n",
    "document_store_200 = ElasticsearchDocumentStore(host=\"localhost\", port = \"9200\", index=\"document_200\",\n",
    "                                           similarity=similarity_type)\n",
    "document_store_300 = ElasticsearchDocumentStore(host=\"localhost\", port = \"9200\", index=\"document_300\",\n",
    "                                           similarity=similarity_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25186bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pdftotext version 4.03 [www.xpdfreader.com]\n",
      "Copyright 1996-2021 Glyph & Cog, LLC\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import TextConverter, PDFToTextConverter, DocxToTextConverter, PreProcessor\n",
    "\n",
    "preprocessor_100 = PreProcessor(\n",
    "    clean_empty_lines=True,\n",
    "    clean_whitespace=True,\n",
    "    clean_header_footer=False,\n",
    "    split_by=\"word\",\n",
    "    split_length=100,\n",
    "    split_respect_sentence_boundary=True,\n",
    ")\n",
    "\n",
    "preprocessor_200 = PreProcessor(\n",
    "    clean_empty_lines=True,\n",
    "    clean_whitespace=True,\n",
    "    clean_header_footer=False,\n",
    "    split_by=\"word\",\n",
    "    split_length=200,\n",
    "    split_respect_sentence_boundary=True,\n",
    ")\n",
    "\n",
    "preprocessor_300 = PreProcessor(\n",
    "    clean_empty_lines=True,\n",
    "    clean_whitespace=True,\n",
    "    clean_header_footer=False,\n",
    "    split_by=\"word\",\n",
    "    split_length=300,\n",
    "    split_respect_sentence_boundary=True,\n",
    ")\n",
    "\n",
    "converter = PDFToTextConverter(remove_numeric_tables=False, valid_languages = [\"en\"])\n",
    "\n",
    "print('OK !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fbfb99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f604e32e",
   "metadata": {},
   "source": [
    "# Set document_store & preprocessor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca25b07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store = document_store_100\n",
    "preprocessor = preprocessor_100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5d8bb3",
   "metadata": {},
   "source": [
    "# Process Raw PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220d9bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_content(content):\n",
    "    content = content.replace('..','.')\n",
    "    content = content.replace('..','.')\n",
    "    content = content.replace('..','.')\n",
    "    content = content.replace('..','.')\n",
    "    content = content.replace('..','.')\n",
    "    content = content.replace('..','.')\n",
    "    content = content.replace('..','.')\n",
    "    content = content.replace('..','.')\n",
    "    content = content.replace('..','.')\n",
    "    content = content.replace('..','.')\n",
    "    return content\n",
    "\n",
    "entity_extractor = EntityExtractor(model_name_or_path=\"dslim/bert-base-NER\")\n",
    "\n",
    "print('OK !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79f9e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'International Regulator'\n",
    "\n",
    "file_list = []\n",
    "for path, subdirs, files in os.walk(root):\n",
    "    for name in files:\n",
    "#         print(os.path.join(path, name))\n",
    "        file_list.append(os.path.join(path, name))\n",
    "    \n",
    "len(file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddcecc1",
   "metadata": {},
   "source": [
    "# Clean Text & NER Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e18d20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list = []\n",
    "for file_name in tqdm(file_list):\n",
    "    doc = converter.convert(file_path = file_name, meta = None)\n",
    "    doc[0]['content'] = clean_content(doc[0]['content'])\n",
    "    docs = preprocessor.process(doc[0])\n",
    "    \n",
    "    keyword = file_name.split('/')[-2]\n",
    "    central_bank = file_name.split('/')[-3]\n",
    "    \n",
    "    for j, doc in enumerate(docs):\n",
    "        doc['meta']['keyword'] = keyword\n",
    "        doc['meta']['central_bank'] = central_bank\n",
    "        doc['meta']['file_name'] = file_name\n",
    "        \n",
    "        content = doc['content']\n",
    "        entities = entity_extractor.extract(\n",
    "            text=content\n",
    "         )\n",
    "        \n",
    "        e_df = pd.DataFrame(entities)\n",
    "        if len(e_df) > 0:\n",
    "            e_df = e_df.groupby('word').first().reset_index()\n",
    "            e_df = e_df.groupby('entity_group')['word'].apply(list).reset_index()\n",
    "            for j in range(len(e_df)):\n",
    "                doc['meta'][e_df['entity_group'].values[j]] = e_df['word'].values[j]\n",
    "\n",
    "        doc_list = doc_list + [doc]\n",
    "#         if j == 6:\n",
    "#             break \n",
    "#     \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97f9df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896b3c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c9678e",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.write_documents(doc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3a6690",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = DensePassageRetriever(\n",
    "    document_store=document_store,\n",
    "    query_embedding_model=\"DPR-retriever/query_encoder\",\n",
    "    passage_embedding_model=\"DPR-retriever/passage_encoder\",\n",
    "    max_seq_len_query=64,\n",
    "    max_seq_len_passage=256,\n",
    "    batch_size=16,\n",
    "    use_gpu=True,\n",
    "    embed_title=True,\n",
    "    use_fast_tokenizers=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68d3107",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.update_embeddings(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929faf7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b1bafc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py38hay]",
   "language": "python",
   "name": "conda-env-py38hay-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
